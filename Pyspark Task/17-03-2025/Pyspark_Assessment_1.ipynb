{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame using Row() and manually define schema.\n",
        "*  Import Row from PySpark.\n",
        "*  Create a list of Row objects with sample data.\n",
        "*  Define a schema manually using StructType.\n",
        "*  Convert the list into a DataFrame and display results."
      ],
      "metadata": {
        "id": "PXrXUNy0HmR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N8wKocQ26A6E"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession,Row"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparksession.Builder() is for building the sparksession i.e. entry-point for spark session and assigning a name: 'Assignment'\n",
        "getOrCreate() : it checks whether any sparksession is having a name as Assignment or not , if not present then it will create a session\n"
      ],
      "metadata": {
        "id": "Oid6ywbA8KOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.Builder().appName(\"Assignment\").getOrCreate()"
      ],
      "metadata": {
        "id": "wQgMbA2U72fA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = [Row(Name = 'Akash', Mentor = 'GnanaSirisha'), Row(Name = 'Pavan Kalyan', Mentor = 'Vinay'),Row(Name = 'Chandrika', Mentor = 'Nusrath'),Row(Name = 'Sahiti ', Mentor = 'Srinivas')]"
      ],
      "metadata": {
        "id": "Dx4T3Zu19o54"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hXlFuXsAOh2",
        "outputId": "86137f88-314f-4040-ea77-6f074d8b1c40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Akash', Mentor='GnanaSirisha'),\n",
              " Row(Name='Pavan Kalyan', Mentor='Vinay'),\n",
              " Row(Name='Chandrika', Mentor='Nusrath'),\n",
              " Row(Name='Sahiti ', Mentor='Srinivas')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# without using any schema\n",
        "df = spark.createDataFrame(data=my_data)"
      ],
      "metadata": {
        "id": "_nNagbhABpFz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFRLa6WSBuZs",
        "outputId": "ab7e52cd-3909-4ce6-c2df-7f921de811ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+\n",
            "|        Name|      Mentor|\n",
            "+------------+------------+\n",
            "|       Akash|GnanaSirisha|\n",
            "|Pavan Kalyan|       Vinay|\n",
            "|   Chandrika|     Nusrath|\n",
            "|     Sahiti |    Srinivas|\n",
            "+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Row() is used to explicitly entering the data but it is much slower but it can work on nested structures\n",
        "\n",
        "Here we are using list but we can also use dict() but it is less efficient"
      ],
      "metadata": {
        "id": "my1GMnBqESfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with using defined schema\n",
        "\n",
        "from pyspark.sql.types import StructType,StructField,StringType"
      ],
      "metadata": {
        "id": "zHhoncTICUpw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_schema = StructType(\n",
        "    [StructField('Name',StringType(),True),\n",
        "     StructField('Mentor',StringType(),True)])"
      ],
      "metadata": {
        "id": "xHHaao41JVe2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame(data=my_data,schema=my_schema)"
      ],
      "metadata": {
        "id": "5THeEjNZJtUl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szwYRTjxJ2Jb",
        "outputId": "a74d2f4e-d2f1-484b-91a5-9b9cfca00d73"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+\n",
            "|        Name|      Mentor|\n",
            "+------------+------------+\n",
            "|       Akash|GnanaSirisha|\n",
            "|Pavan Kalyan|       Vinay|\n",
            "|   Chandrika|     Nusrath|\n",
            "|     Sahiti |    Srinivas|\n",
            "+------------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
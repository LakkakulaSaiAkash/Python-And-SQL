{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Work with StructType and StructField for nested schema definitions.\n",
        "- Define a nested schema using StructType and StructField.\n",
        "- Create a JSON-like dataset with nested fields.\n",
        "- Load the dataset into a PySpark DataFrame.\n",
        "- Extract and transform nested fields using selectExpr()."
      ],
      "metadata": {
        "id": "OPjOLl-n9M0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52j6wytftRE7"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession,Row"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Assessment3').getOrCreate()"
      ],
      "metadata": {
        "id": "x3zHUy6BqxxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructField ,StructType"
      ],
      "metadata": {
        "id": "rLX1YgdcuBO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assess3_data = [Row(id = 1, name = 'Akash' , dept = ['CSE','AIML']),\n",
        "#                 Row(id = 2, name = 'Venkatesh' , dept = ['CSE','CORE']),\n",
        "#                 Row(id = 3, name = 'Rohith' , dept = ['CSE','CS'])]\n"
      ],
      "metadata": {
        "id": "5gZBJwQBuWcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "why mentioning multiline = true solves the issue ?"
      ],
      "metadata": {
        "id": "-AZp4Q9NqBFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Without **multiLine=True**, Spark reads each line separately and expects it to be a valid JSON object.\n",
        "\n",
        "\n",
        "*   With **multiLine=True,** Spark understands that the entire file is one JSON object, even if it spans multiple lines.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iDDexe8Pv9vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = spark.read.option('multiline','True').json(path = \"/content/sample1.json\");"
      ],
      "metadata": {
        "id": "iPhF-yj9aPR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Ve3wP-jC5T",
        "outputId": "67bc20d0-b066-4002-dc01-4ac906bbad58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|             brewing|              coffee|\n",
            "+--------------------+--------------------+\n",
            "|{{Brewing Co., 10...|{{Coffee Co., 101...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the data is in JSON , now to convert the JSON file into well-defined table we'll use the EXPLODE()\n",
        "\n"
      ],
      "metadata": {
        "id": "UWHUutUdl0Fx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode() - The explode() function in PySpark is used to transform an array column into multiple rows, where each element in the array becomes its own row.\n",
        "\n"
      ],
      "metadata": {
        "id": "hEh58CBsAEVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-zVPWIT5X-Q",
        "outputId": "1d872f5c-ed31-4c2f-b735-7b4564ed5012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- brewing: struct (nullable = true)\n",
            " |    |-- country: struct (nullable = true)\n",
            " |    |    |-- company: string (nullable = true)\n",
            " |    |    |-- id: long (nullable = true)\n",
            " |    |-- region: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- id: long (nullable = true)\n",
            " |    |    |    |-- name: string (nullable = true)\n",
            " |-- coffee: struct (nullable = true)\n",
            " |    |-- country: struct (nullable = true)\n",
            " |    |    |-- company: string (nullable = true)\n",
            " |    |    |-- id: long (nullable = true)\n",
            " |    |-- region: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- id: long (nullable = true)\n",
            " |    |    |    |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,explode"
      ],
      "metadata": {
        "id": "hR9MJ2zru6kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_json_data = json_data.select(explode(col('coffee.region')).alias('Coffee_region'),\n",
        "                                     explode(col('brewing.region')).alias('brewing_region'),\n",
        "                                     col('coffee.country.id').alias('Coffee_country_id'),\n",
        "                                     col('coffee.country.company').alias('Coffee_country_name'),\n",
        "                                     col('brewing.country.id').alias('Brewing_country_id'),\n",
        "                                     col('brewing.country.company').alias('Brewing_country_name'))"
      ],
      "metadata": {
        "id": "Q_rNkL45mRI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_json_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OUUE0Y5r7ue",
        "outputId": "bb64ffd6-6697-4454-b97d-1528c7a35564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------+-----------------+-------------------+------------------+--------------------+\n",
            "|     Coffee_region|brewing_region|Coffee_country_id|Coffee_country_name|Brewing_country_id|Brewing_country_name|\n",
            "+------------------+--------------+-----------------+-------------------+------------------+--------------------+\n",
            "|{1, Latin America}|   {3, Europe}|              101|         Coffee Co.|               102|         Brewing Co.|\n",
            "|{1, Latin America}|     {4, Asia}|              101|         Coffee Co.|               102|         Brewing Co.|\n",
            "|       {2, Africa}|   {3, Europe}|              101|         Coffee Co.|               102|         Brewing Co.|\n",
            "|       {2, Africa}|     {4, Asia}|              101|         Coffee Co.|               102|         Brewing Co.|\n",
            "+------------------+--------------+-----------------+-------------------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new_json_data = json_data.select(\n",
        "#     explode(col('coffee.region')).alias('Coffee_region'),\n",
        "#     col(\"Coffee_region.id\").alias(\"Coffee_region_id\"),\n",
        "#     col(\"Coffee_region.name\").alias(\"Coffee_region_name\"),\n",
        "#     explode(col('brewing.region')).alias('Brewing_region'),\n",
        "#     col(\"Brewing_region.id\").alias(\"Brewing_region_id\"),\n",
        "#     col(\"Brewing_region.name\").alias(\"Brewing_region_name\"),\n",
        "#     col('coffee.country.id').alias('Coffee_country_id'),\n",
        "#     col('coffee.country.company').alias('Coffee_country_name'),\n",
        "#     col('brewing.country.id').alias('Brewing_country_id'),\n",
        "#     col('brewing.country.company').alias('Brewing_country_name')\n",
        "# )"
      ],
      "metadata": {
        "id": "2G7gGJt0yZQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1 = json_data.withColumn('coffee_exploded', explode(col('coffee.region')))\\\n",
        "                          .withColumn('brewing_exploded', explode(col('brewing.region')))\\\n",
        "                          .withColumn('coffee_region_id', col('coffee_exploded.id'))\\\n",
        "                          .withColumn('coffee_region_name', col('coffee_exploded.name'))\\\n",
        "                          .withColumn('coffee_country_id', col('coffee.country.id'))\\\n",
        "                          .withColumn('coffee_country_name', col('coffee.country.company'))\\\n",
        "                          .withColumn('brewing_region_id', col('brewing_exploded.id'))\\\n",
        "                          .withColumn('brewing_region_name', col('brewing_exploded.name'))\\\n",
        "                          .withColumn('brewing_country_id', col('brewing.country.id'))\\\n",
        "                          .withColumn('brewing_country_name', col('brewing.country.company'))\\\n",
        "                          .drop('coffee_exploded', 'brewing_exploded', 'coffee', 'brewing')"
      ],
      "metadata": {
        "id": "Kf-L_yDl3-wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VpB1gHgr2NO",
        "outputId": "c5821db6-23e7-4be8-b5d9-04679e84cfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "|coffee_region_id|coffee_region_name|coffee_country_id|coffee_country_name|brewing_region_id|brewing_region_name|brewing_country_id|brewing_country_name|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "|               1|     Latin America|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|\n",
            "|               1|     Latin America|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|\n",
            "|               2|            Africa|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|\n",
            "|               2|            Africa|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data = json_data.withColumn('coffee_exploded',explode(col('coffee.region')))\\\n",
        "                          .withColumn('brewing_exploded',explode(col('brewing.region')))\\\n",
        "                          .select(col('coffee_exploded.id').alias('coffee_region_id'),\n",
        "                                  col('coffee_exploded.name').alias('coffee_region_name'),\n",
        "                                  col('coffee.country.id').alias('coffee_country_id'),\n",
        "                                  col('coffee.country.company').alias('coffee_country_name'),\n",
        "                                  col('brewing_exploded.id').alias('brewing_region_id'),\n",
        "                                  col('brewing_exploded.name').alias('brewing_region_name'),\n",
        "                                  col('brewing.country.id').alias('brewing_country_id'),\n",
        "                                  col('brewing.country.company').alias('brewing_country_name'))"
      ],
      "metadata": {
        "id": "7rI72WBnrPs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGwAzLuurPjM",
        "outputId": "45648a85-ac3a-4b4e-bc6c-aefbc6b2c755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "|coffee_region_id|coffee_region_name|coffee_country_id|coffee_country_name|brewing_region_id|brewing_region_name|brewing_country_id|brewing_country_name|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "|               1|     Latin America|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|\n",
            "|               1|     Latin America|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|\n",
            "|               2|            Africa|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|\n",
            "|               2|            Africa|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**selectExpr()** is a method in PySpark that allows you to write SQL-like expressions inside select().\n",
        "\n",
        "It is useful when you want to:\n",
        "\n",
        "1.   Perform column selection using SQL expressions.\n",
        "2.  Apply transformations like alias, CAST, and CASE WHEN directly.\n",
        "3.  Avoid using col() or withColumn() for simple expressions.\n",
        "\n",
        "- In these cases selectEXPR() is better than SELECT()\n",
        "\n"
      ],
      "metadata": {
        "id": "gHk8LxTXsUnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv4PVh2_sHDz",
        "outputId": "4f5b6f91-4a2c-43f6-da7b-626d5c083a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- coffee_region_id: long (nullable = true)\n",
            " |-- coffee_region_name: string (nullable = true)\n",
            " |-- coffee_country_id: long (nullable = true)\n",
            " |-- coffee_country_name: string (nullable = true)\n",
            " |-- brewing_region_id: long (nullable = true)\n",
            " |-- brewing_region_name: string (nullable = true)\n",
            " |-- brewing_country_id: long (nullable = true)\n",
            " |-- brewing_country_name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As ID's all are in LONG so we'll cast into Integer"
      ],
      "metadata": {
        "id": "JjnAEpBSs6_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new_json_data1.selectExpr('cast(coffee_region_id as int)',\n",
        "#                           'cast(coffee_country_id as int)',\n",
        "#                           'cast(brewing_region_id as int)',\n",
        "#                           'cast(brewing_country_id as int)')"
      ],
      "metadata": {
        "id": "UF3WQ792sw04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1=new_json_data1.selectExpr(\n",
        "                                         'CAST(coffee_region_id as int) as coffee_region_id',\n",
        "                                         'coffee_region_name',\n",
        "                                         'cast(coffee_country_id as int) as coffee_country_id',\n",
        "                                         'coffee_country_name',\n",
        "                                         'cast(brewing_region_id as int) as brewing_region_id',\n",
        "                                         'brewing_region_name',\n",
        "                                         'cast(brewing_country_id as int) as brewing_country_id',\n",
        "                                         'brewing_country_name')"
      ],
      "metadata": {
        "id": "fINuNSh2t5u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fXfiQB-swlr",
        "outputId": "40c5a9d9-e02b-4354-dd95-55e0426fb16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- coffee_region_id: integer (nullable = true)\n",
            " |-- coffee_region_name: string (nullable = true)\n",
            " |-- coffee_country_id: integer (nullable = true)\n",
            " |-- coffee_country_name: string (nullable = true)\n",
            " |-- brewing_region_id: integer (nullable = true)\n",
            " |-- brewing_region_name: string (nullable = true)\n",
            " |-- brewing_country_id: integer (nullable = true)\n",
            " |-- brewing_country_name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2CB285ouD3z",
        "outputId": "cc13bc5c-8729-470e-a1b0-7365bde4a655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "|coffee_region_id|coffee_region_name|coffee_country_id|coffee_country_name|brewing_region_id|brewing_region_name|brewing_country_id|brewing_country_name|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "|               1|     Latin America|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|\n",
            "|               1|     Latin America|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|\n",
            "|               2|            Africa|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|\n",
            "|               2|            Africa|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SYNTAX**\n",
        "\n",
        "```\n",
        "df.selectExpr(\n",
        "    \"CASE \" +\n",
        "    \"WHEN column_name = 'value1' THEN 'result1' \" +\n",
        "    \"WHEN column_name = 'value2' THEN 'result2' \" +\n",
        "    \"ELSE 'default_result' \" +\n",
        "    \"END AS new_column_name\"\n",
        ").show()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1pYxdwnDxqZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1.selectExpr(\n",
        "    \"CASE \" +\n",
        "    \"WHEN coffee_region_name = 'Latin America' THEN 'LA' \" +\n",
        "    \"WHEN coffee_region_name = 'Africa' THEN 'AF' \" +\n",
        "    \"ELSE 'NA' \" +\n",
        "    \"END AS coffee_shrt_name\"\n",
        ").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUkGrQBxxaNt",
        "outputId": "8d59114f-7c13-4938-9a67-ac590250393e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|coffee_shrt_name|\n",
            "+----------------+\n",
            "|              LA|\n",
            "|              LA|\n",
            "|              AF|\n",
            "|              AF|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final_new_json_data = new_json_data1.union(new_json_data1.selectExpr(\n",
        "#     \"CASE \" +\n",
        "#     \"WHEN coffee_region_name = 'Latin America' THEN 'LA' \" +\n",
        "#     \"WHEN coffee_region_name = 'Africa' THEN 'AF' \" +\n",
        "#     \"ELSE 'NA' \" +\n",
        "#     \"END AS coffee_shrt_name\"\n",
        "# ))\n",
        "\n",
        "# THIS METHOD CANNOT BE DONE\n",
        "\n",
        "'''perform a union between two DataFrames with different numbers\n",
        " of columns. new_json_data1 has 8 columns,\n",
        "  while new_json_data1.selectExpr(...) results in a DataFrame\n",
        "  with only 1 column (coffee_shrt_name).\n",
        "  The union operation in PySpark requires both DataFrames\n",
        "   to have the same number of columns.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uW8HQnjvwnkZ",
        "outputId": "24b5b7b6-86a0-4c5f-e547-d43322d6b252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'perform a union between two DataFrames with different numbers\\n of columns. new_json_data1 has 8 columns,\\n  while new_json_data1.selectExpr(...) results in a DataFrame \\n  with only 1 column (coffee_shrt_name). \\n  The union operation in PySpark requires both DataFrames\\n   to have the same number of columns.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new_json_data=new_json_data.withColumn(\n",
        "#     \"coffee_shrt_name\",\n",
        "#     (\n",
        "#         \"CASE \" +\n",
        "#         \"WHEN coffee_region_name = 'Latin America' THEN 'LA' \" +\n",
        "#         \"WHEN coffee_region_name = 'Africa' THEN 'AF' \" +\n",
        "#         \"ELSE 'NA' \" +\n",
        "#         \"END \"\n",
        "#     )\n",
        "# )\n",
        "\n",
        "# here the second argument should be a column name but here\n",
        "# CASE WHEN expression is being considered as a string so that's why it not working"
      ],
      "metadata": {
        "id": "kAKfZ58C0LyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "\n",
        "new_json_data1=new_json_data1.withColumn(\n",
        "    \"coffee_shrt_name\",\n",
        "    expr(\n",
        "        \"CASE \" +\n",
        "        \"WHEN coffee_region_name = 'Latin America' THEN 'LA' \" +\n",
        "        \"WHEN coffee_region_name = 'Africa' THEN 'AF' \" +\n",
        "        \"ELSE 'NA' \" +\n",
        "        \"END \"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "oQmhbnocyZxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json_data1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7BPfTiU0I0l",
        "outputId": "07746aa4-0da8-426c-88a7-b09bfa654d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+----------------+\n",
            "|coffee_region_id|coffee_region_name|coffee_country_id|coffee_country_name|brewing_region_id|brewing_region_name|brewing_country_id|brewing_country_name|coffee_shrt_name|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+----------------+\n",
            "|               1|     Latin America|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|              LA|\n",
            "|               1|     Latin America|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|              LA|\n",
            "|               2|            Africa|              101|         Coffee Co.|                3|             Europe|               102|         Brewing Co.|              AF|\n",
            "|               2|            Africa|              101|         Coffee Co.|                4|               Asia|               102|         Brewing Co.|              AF|\n",
            "+----------------+------------------+-----------------+-------------------+-----------------+-------------------+------------------+--------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}